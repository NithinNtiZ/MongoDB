# MongoDB Sharded Replica Set Configuration File

# Specify the name of the replica set
replication:
  replSetName: myReplicaSet

# Set the path for data and log files
systemLog:
  path: /var/log/mongodb/mongod.log
  destination: file
storage:
  dbPath: /data/db

# Specify the hostname and port for each node in the cluster
net:
  bindIp: 0.0.0.0
  port: 27017

# Set the priority and voting of each node
# Higher priority means more important
# Higher votes means more likely to be elected primary
# In this example, node1 is the primary and nodes 2 and 3 are secondaries
# The arbiter does not have a vote and is only used for tie-breaking
replication:
  replSetName: myReplicaSet
  members:
    - _id: 0
      host: node1:27017
      priority: 2
      votes: 1
    - _id: 1
      host: node2:27017
      priority: 1
      votes: 1
    - _id: 2
      host: node3:27017
      priority: 1
      votes: 1
    - _id: 3
      host: arbiter:27017
      arbiterOnly: true

# Set the write concern to ensure data consistency
writeConcern:
  w: 1

# Set the storage engine to WiredTiger
storage:
  engine: wiredTiger

# Sharding configuration
sharding:
  clusterRole: configsvr
  configDB: configsvr1:27017,configsvr2:27017,configsvr3:27017

# Shard the database and collection
# In this example, the test database is sharded on the field "shardKey"
# and the collection "data" is sharded across two shards: shard1 and shard2
sharding:
  db: test
  shardedCollections:
    - name: data
      key: { shardKey: 1 }
  shards:
    - _id: shard1
      host: shard1/node1:27017,node2:27017
    - _id: shard2
      host: shard2/node3:27017,node4:27017s